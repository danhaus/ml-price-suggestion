{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = { \n",
    "            'data_size': None, # size of data subset after shuffle is performed\n",
    "            'test_size': 0.25, # fraction of data set to be assigned as test data\n",
    "            'save_env': False # save environment\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data: load dataset, shuffle it and take subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = pd.read_csv(f'{PATH}train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data_shuffled = shuffle(data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_shuffled.iloc[:settings['data_size'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split category_name into main_cat, subcat_1 and subcat_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: BuryBuryZymon at https://www.kaggle.com/maheshdadhich/i-will-sell-everything-for-free-0-55\n",
    "def split_cat(text):\n",
    "    try: return text.split(\"/\")\n",
    "    except: return (\"No Label\", \"No Label\", \"No Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:,'main_cat'], data.loc[:,'subcat_1'], data.loc[:,'subcat_2'] = \\\n",
    "zip(*data.loc[:,'category_name'].apply(lambda x: split_cat(x)))\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique fields:\\n\")\n",
    "\n",
    "print(\"main_cat: \\t%d\" % data['main_cat'].nunique())\n",
    "print(\"subcat_1: \\t%d\" % data['subcat_1'].nunique())\n",
    "print(\"subcat_2: \\t%d\" % data['subcat_2'].nunique())\n",
    "print(\"brand_name: \\t%d\" % data['brand_name'].nunique())\n",
    "print()\n",
    "\n",
    "print(\"%d items have no category\" % len(data.loc[data['main_cat'] == 'No Label']))\n",
    "print(\"%d items have no brand\" % data['brand_name'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerically represent features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_id: copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new DataFrame called data_num for numerical representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = pd.DataFrame(data.loc[:,'train_id'], columns=['train_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### name: represent name by its length as name_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_len = data['name'].str.len()\n",
    "data_num.loc[:,'name_len'] = name_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item_condition_id, price, shipping: copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num[['item_condition_id', 'price', 'shipping']] = data.loc[:,['item_condition_id', 'price', 'shipping']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent item_description by its length as item_description_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_description_len = data.loc[:,'item_description'].str.len()\n",
    "data_num['item_description_len'] = item_description_len\n",
    "\n",
    "# Replace NaN in data_num.item_description_len column by zeros\n",
    "data_num['item_description_len'] = data_num['item_description_len'].fillna(0)\n",
    "\n",
    "# Change data type of this column to uint16 provided the max val is less than 65535\n",
    "if (data_num.item_description_len.max() < 65535):\n",
    "    data_num['item_description_len'] = data_num['item_description_len'].astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function for making binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binary_columns(df_str, df_num, column_name):\n",
    "    \"\"\"\n",
    "    Turns a single column named column_name (with various categories) into m binary columns, where m is the number\n",
    "    of unique values in the original column. For each sample, the value for all new columns is 0 apart the one\n",
    "    that matches the value of the original column. Names of new binary columns are formed as follows:\n",
    "    column_name + '_' + str(original column value)\n",
    "    Inputs:\n",
    "        two pandas DataFrames: df_str where a single column contains information about given category\n",
    "                               df_num that will later contain many binary columns\n",
    "        column_name: name of the column that will be split into several binary columns\n",
    "    Returns nothing. It appends the collumns directly into df_num to increase performance.\n",
    "    \"\"\"\n",
    "    m = len(df_str)\n",
    "    if (m != len(df_num)):\n",
    "        raise Exception(\"df_str and df_num must have the same size.\")\n",
    " \n",
    "    categories = df_str[column_name].unique()\n",
    "\n",
    "    from tqdm import tqdm_notebook # progress bar\n",
    "\n",
    "    # Create a new feature for each category and initialize it to 0\n",
    "    for i in tqdm_notebook(categories, desc='1/2'):\n",
    "        df_num[column_name + '_' + str(i)] = np.zeros((m, 1), dtype=np.int8)\n",
    "\n",
    "#     Loop thorugh all rows and assign 1 to the column whose name is the same as category\n",
    "    for i in tqdm_notebook(df_str.index, desc='2/2'): # loop through all rows\n",
    "        category = str(df_str.at[i, column_name])\n",
    "        df_num.at[i, column_name + '_' + category] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### brand_name: for each unique one create new binary feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_binary_columns(data, data_num, 'brand_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main_cat, subcat_1, subcat_2: for each unique one create new binary feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_binary_columns(data, data_num, 'main_cat')\n",
    "make_binary_columns(data, data_num, 'subcat_1')\n",
    "make_binary_columns(data, data_num, 'subcat_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data and extract X, y and train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data_num, test_size = settings['test_size'], random_state=None) # randomly split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.pop('price')\n",
    "y_test = test.pop('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pop id_train from both training and test data set\n",
    "\n",
    "id_train = X_train.pop('train_id')\n",
    "id_test = X_test.pop('train_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_train) # Compute the mean adn std of training data to be used for future scaling\n",
    "\n",
    "X_train_scaled_ar = scaler.transform(X_train)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled_ar, index=X_train.index, columns=X_train.columns)\n",
    "del X_train_scaled_ar\n",
    "\n",
    "X_test_scaled_ar = scaler.transform(X_test)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled_ar, index=X_test.index, columns=X_test.columns)\n",
    "del X_test_scaled_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (settings['save_env']):\n",
    "    import dill                            #pip install dill --user\n",
    "    dill.dump_session('splittedData.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete data that are not needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' By Fred Cirera, after https://stackoverflow.com/a/1094933/1870254'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name,value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name,sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_num, train, test, X_train, X_test, data_full, data_shuffled, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance measure: RMSE\n",
    "\n",
    "$$\\text{RMSE} \\left( \\mathbf{Y} , \\mathbf{\\hat{Y}} \\right) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n \\left( y_i - \\hat{y_i} \\right)^2 } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_test, y_pred):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lnr_regr = LinearRegression(n_jobs=-1)\n",
    "print(\"Trainig...\")\n",
    "lnr_regr.fit(X_train_scaled, y_train)\n",
    "print(\"Training done.\")\n",
    "\n",
    "if (settings['save_env']):\n",
    "    dill.dump_session('linearModel.pkl')\n",
    "    \n",
    "# Make predictions and report train and test RMSEs\n",
    "\n",
    "print(\"Evaluating performance on the training set...\")\n",
    "pred_train = lnr_regr.predict(X_train_scaled)\n",
    "rmse_train = rmse(y_train, pred_train)\n",
    "print(\"Training set RMSE: %.2f\" % rmse_train)\n",
    "\n",
    "print(\"Evaluating performance on the test test...\")\n",
    "pred_test = lnr_regr.predict(X_test_scaled)\n",
    "rmse_test = rmse(y_test, pred_test)\n",
    "print(\"Test set RMSE: %.2f\" % rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dill.load_session('linearModel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
