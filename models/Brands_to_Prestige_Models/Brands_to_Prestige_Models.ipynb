{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = { \n",
    "            'data_size': None, # size of data subset after shuffle is performed\n",
    "            'test_size': 0.25, # fraction of data set to be assigned as test data\n",
    "            'del': True, # Delete variables that are no longer needed to proceed in computations to save place\n",
    "            'random_state': { # Set random states so that the results are repeatable\n",
    "                'shuffle': 42, # sklearn's shuffle method\n",
    "                'split': 17 # sklearn's train_test_split method\n",
    "            }\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data: load dataset, shuffle it and take subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = pd.read_csv(f'{PATH}prestige.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data = shuffle(data_full, random_state=settings['random_state']['shuffle'])\n",
    "\n",
    "if (settings['del']):\n",
    "    del data_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split category_name into main_cat, subcat_1 and subcat_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: BuryBuryZymon at https://www.kaggle.com/maheshdadhich/i-will-sell-everything-for-free-0-55\n",
    "def split_cat(text):\n",
    "    try: return text.split(\"/\")\n",
    "    except: return (\"No Label\", \"No Label\", \"No Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:,'main_cat'], data.loc[:,'subcat_1'], data.loc[:,'subcat_2'] = \\\n",
    "zip(*data.loc[:,'category_name'].apply(lambda x: split_cat(x)))\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerically represent features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_id: copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new DataFrame called data_num for numerical representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = pd.DataFrame(data.loc[:,'train_id'], columns=['train_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### name: represent name by its length as name_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num.loc[:,'name_len'] = data['name'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item_condition_id, price, shipping: copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num[['item_condition_id', 'price', 'shipping']] = data.loc[:,['item_condition_id', 'price', 'shipping']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent item_description by its length as item_description_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_description_len = data.loc[:,'item_description'].str.len()\n",
    "data_num['item_description_len'] = item_description_len\n",
    "\n",
    "# Replace NaN in data_num.item_description_len column by zeros\n",
    "data_num['item_description_len'] = data_num['item_description_len'].fillna(0)\n",
    "\n",
    "# Change data type of this column to uint16 provided the max val is less than 65535\n",
    "if (data_num.item_description_len.max() < 65535):\n",
    "    data_num['item_description_len'] = data_num['item_description_len'].astype(np.uint16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prestige, prestige_reliability: copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num.loc[['prestige', 'prestige_reliability']] = data.loc[['prestige', 'prestige_reliability']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function for making binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binary_columns(df_str, df_num, column_name):\n",
    "    \"\"\"\n",
    "    Turns a single column named column_name (with various categories) into m binary columns, where m is the number\n",
    "    of unique values in the original column. For each sample, the value for all new columns is 0 apart the one\n",
    "    that matches the value of the original column. Names of new binary columns are formed as follows:\n",
    "    column_name + '_' + str(original column value)\n",
    "    Inputs:\n",
    "        two pandas DataFrames: df_str where a single column contains information about given category\n",
    "                               df_num that will later contain many binary columns\n",
    "        column_name: name of the column that will be split into several binary columns\n",
    "    Returns nothing. It appends the collumns directly into df_num to increase performance.\n",
    "    \"\"\"\n",
    "    m = len(df_str)\n",
    "    if (m != len(df_num)):\n",
    "        raise Exception(\"df_str and df_num must have the same size.\")\n",
    " \n",
    "    categories = df_str[column_name].unique()\n",
    "\n",
    "    from tqdm import tqdm_notebook # progress bar\n",
    "\n",
    "    # Create a new feature for each category and initialize it to 0\n",
    "    for i in tqdm_notebook(categories, desc='1/2'):\n",
    "        df_num[column_name + '_' + str(i)] = np.zeros((m, 1), dtype=np.int8)\n",
    "\n",
    "#     Loop thorugh all rows and assign 1 to the column whose name is the same as category\n",
    "    for i in tqdm_notebook(df_str.index, desc='2/2'): # loop through all rows\n",
    "        category = str(df_str.at[i, column_name])\n",
    "        df_num.at[i, column_name + '_' + category] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main_cat, subcat_1, subcat_2: for each unique one create new binary feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_binary_columns(data, data_num, 'main_cat')\n",
    "make_binary_columns(data, data_num, 'subcat_1')\n",
    "make_binary_columns(data, data_num, 'subcat_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (settings['del']):\n",
    "    del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data and extract X, y and train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_unscaled, X_test_unscaled = train_test_split(data_num, test_size = settings['test_size'], random_state=settings['random_state']['split']) # randomly split data\n",
    "# ! X_train_unscaled and X_test_unscaled STILL CONTAINS PRICE AT THIS MOMENT !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (settings['del']):\n",
    "    del data_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pop price from X_train and X_test\n",
    "y_train = X_train_unscaled.pop('price')\n",
    "y_test = X_test_unscaled.pop('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pop id_train from both training and test data set\n",
    "id_train = X_train_unscaled.pop('train_id')\n",
    "id_test = X_test_unscaled.pop('train_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "X_train = X_train_unscaled.copy()\n",
    "X_test = X_test_unscaled.copy()\n",
    "\n",
    "columns_to_scale = ['name_len', 'item_condition_id', 'item_description_len']\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_train_unscaled[columns_to_scale]) # Compute the mean adn std of training data to be used for future scaling\n",
    "\n",
    "X_train[columns_to_scale] = pd.DataFrame(scaler.transform(X_train_unscaled[columns_to_scale]), index=X_train_unscaled.index, columns=columns_to_scale)\n",
    "if (settings['del']):\n",
    "    del X_train_unscaled\n",
    "\n",
    "X_test[columns_to_scale] = pd.DataFrame(scaler.transform(X_test_unscaled[columns_to_scale]), index=X_test_unscaled.index, columns=columns_to_scale)\n",
    "if (settings['del']):\n",
    "    del X_test_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_unscaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_unscaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.to_csv('X_train.csv')\n",
    "# X_train_scaled.to_csv('X_train_scaled.csv')\n",
    "# X_test.to_csv('X_test.csv')\n",
    "# X_test_scaled.to_csv('X_test_scaled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check size of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       X_train:   6.1GiB\n",
      "                        X_test:   2.0GiB\n",
      "          item_description_len:  62.6MiB\n",
      "                       y_train:  17.0MiB\n",
      "                      id_train:  17.0MiB\n",
      "                        y_test:   5.7MiB\n",
      "                       id_test:   5.7MiB\n",
      "                           ___:  28.6KiB\n",
      "                           _29:  28.6KiB\n",
      "                             _:  28.6KiB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' By Fred Cirera, after https://stackoverflow.com/a/1094933/1870254'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name,value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name,sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance measure: RMSE\n",
    "\n",
    "$$\\text{RMSE} \\left( \\mathbf{Y} , \\mathbf{\\hat{Y}} \\right) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n \\left( y_i - \\hat{y_i} \\right)^2 } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_test, y_pred):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply linear regression to the full trainin set, compute training and test RMSE and add them to the file created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lnr_regr = LinearRegression(n_jobs=-1)\n",
    "print(\"Trainig...\")\n",
    "lnr_regr.fit(X_train, y_train)\n",
    "print(\"Training done.\")\n",
    "    \n",
    "# Make predictions and report train and test RMSEs\n",
    "\n",
    "print(\"Evaluating performance on the training set...\")\n",
    "pred_train = lnr_regr.predict(X_train)\n",
    "rmse_train = rmse(y_train, pred_train)\n",
    "print(\"Training set RMSE: %.2f\" % rmse_train)\n",
    "\n",
    "print(\"Evaluating performance on the test test...\")\n",
    "pred_test = lnr_regr.predict(X_test)\n",
    "rmse_test = rmse(y_test, pred_test)\n",
    "print(\"Test set RMSE: %.2f\" % rmse_test)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
