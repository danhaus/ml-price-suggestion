{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory usage for jupyter\n",
    "!pip install nbresuse\n",
    "# progress bar\n",
    "!pip install tqdm\n",
    "# other libraries\n",
    "!pip install pandas numpy sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = { \n",
    "            'data_size': None, # size of data subset after shuffle is performed\n",
    "            'test_size': 0.25, # fraction of data set to be assigned as test data\n",
    "            'save_env': False, # save environment\n",
    "            'del': True, # Delete variables that are no longer needed to proceed in computations to save place\n",
    "            'filename_str': 'learning_curve.csv', # File for saving training and test RMSEs, this is appended to current date string (yymmdd)\n",
    "            'learning_curve': { # parameters to generate learning_curve\n",
    "                'start': int(5e4), # training set start size (including)\n",
    "                'stop': int(1e6 + 2.5e4), # traing set stop size (excluding)\n",
    "                'step': int(2.5e4)  # increase between iterations\n",
    "#                 'start': int(5e1), # training set start size (including)\n",
    "#                 'stop': int(1e3 + 2.5e1), # traing set stop size (excluding)\n",
    "#                 'step': int(2.5e1)  # increase between iterations\n",
    "                              },\n",
    "            'random_state': { # Set random states so that the results are repeatable\n",
    "                'shuffle': 42, # sklearn's shuffle method\n",
    "                'split': 17 # sklearn's train_test_split method\n",
    "            }\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data: load dataset, shuffle it and take subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = pd.read_csv(f'{PATH}train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "3         3                Leather Horse Statues                  1   \n",
       "4         4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN   10.0   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
       "2                        Women/Tops & Blouses/Blouse     Target   10.0   \n",
       "3                 Home/Home Décor/Home Décor Accents        NaN   35.0   \n",
       "4                            Women/Jewelry/Necklaces        NaN   44.0   \n",
       "\n",
       "   shipping                                   item_description  \n",
       "0         1                                 No description yet  \n",
       "1         0  This keyboard is in great condition and works ...  \n",
       "2         1  Adorable top with a hint of lace and a key hol...  \n",
       "3         1  New with tags. Leather horses. Retail for [rm]...  \n",
       "4         0          Complete with certificate of authenticity  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1482535"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data_shuffled = shuffle(data_full, random_state=settings['random_state']['shuffle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (settings['del']):\n",
    "    del data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_shuffled.iloc[:settings['data_size'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (settings['del']):\n",
    "    del data_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1482535"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>777341</th>\n",
       "      <td>777341</td>\n",
       "      <td>F/ship 4 Totoro Washi + 1 pen</td>\n",
       "      <td>1</td>\n",
       "      <td>Handmade/Paper Goods/Stationery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This listing is for all 4 Totoro washi tape fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463629</th>\n",
       "      <td>1463629</td>\n",
       "      <td>UCLA Men's Bundle + Shorts</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Other/Other</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7 items. 1: XL. 2: 2XL. 3:2XL. 4: XL. 5: 2XL. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350669</th>\n",
       "      <td>350669</td>\n",
       "      <td>Listing for lol</td>\n",
       "      <td>1</td>\n",
       "      <td>Beauty/Makeup/Lips</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>- sunglasses and necklace :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310222</th>\n",
       "      <td>310222</td>\n",
       "      <td>25 pcs kawaii sticker flakes</td>\n",
       "      <td>1</td>\n",
       "      <td>Kids/Toys/Arts &amp; Crafts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>I ordered a bunch of stickers so you will reci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759257</th>\n",
       "      <td>759257</td>\n",
       "      <td>Chanel Mini Lipgloss Set</td>\n",
       "      <td>2</td>\n",
       "      <td>Beauty/Makeup/Lips</td>\n",
       "      <td>Chanel</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand new never used authentic Mini Lipgloss g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_id                           name  item_condition_id  \\\n",
       "777341     777341  F/ship 4 Totoro Washi + 1 pen                  1   \n",
       "1463629   1463629     UCLA Men's Bundle + Shorts                  1   \n",
       "350669     350669                Listing for lol                  1   \n",
       "310222     310222   25 pcs kawaii sticker flakes                  1   \n",
       "759257     759257       Chanel Mini Lipgloss Set                  2   \n",
       "\n",
       "                           category_name brand_name  price  shipping  \\\n",
       "777341   Handmade/Paper Goods/Stationery        NaN   12.0         1   \n",
       "1463629                Women/Other/Other     Adidas   76.0         1   \n",
       "350669                Beauty/Makeup/Lips        NaN   12.0         1   \n",
       "310222           Kids/Toys/Arts & Crafts        NaN    3.0         1   \n",
       "759257                Beauty/Makeup/Lips     Chanel   30.0         1   \n",
       "\n",
       "                                          item_description  \n",
       "777341   This listing is for all 4 Totoro washi tape fo...  \n",
       "1463629  7 items. 1: XL. 2: 2XL. 3:2XL. 4: XL. 5: 2XL. ...  \n",
       "350669                        - sunglasses and necklace :)  \n",
       "310222   I ordered a bunch of stickers so you will reci...  \n",
       "759257   Brand new never used authentic Mini Lipgloss g...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split category_name into main_cat, subcat_1 and subcat_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: BuryBuryZymon at https://www.kaggle.com/maheshdadhich/i-will-sell-everything-for-free-0-55\n",
    "def split_cat(text):\n",
    "    try: return text.split(\"/\")\n",
    "    except: return (\"No Label\", \"No Label\", \"No Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:,'main_cat'], data.loc[:,'subcat_1'], data.loc[:,'subcat_2'] = \\\n",
    "zip(*data.loc[:,'category_name'].apply(lambda x: split_cat(x)))\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique fields:\\n\")\n",
    "\n",
    "print(\"main_cat: \\t%d\" % data['main_cat'].nunique())\n",
    "print(\"subcat_1: \\t%d\" % data['subcat_1'].nunique())\n",
    "print(\"subcat_2: \\t%d\" % data['subcat_2'].nunique())\n",
    "print(\"brand_name: \\t%d\" % data['brand_name'].nunique())\n",
    "print()\n",
    "\n",
    "print(\"%d items have no category\" % len(data.loc[data['main_cat'] == 'No Label']))\n",
    "print(\"%d items have no brand\" % data['brand_name'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerically represent features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_id: copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new DataFrame called data_num for numerical representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = pd.DataFrame(data.loc[:,'train_id'], columns=['train_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### name: represent name by its length as name_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num.loc[:,'name_len'] = data['name'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item_condition_id, price, shipping: copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num[['item_condition_id', 'price', 'shipping']] = data.loc[:,['item_condition_id', 'price', 'shipping']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent item_description by its length as item_description_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_description_len = data.loc[:,'item_description'].str.len()\n",
    "data_num['item_description_len'] = item_description_len\n",
    "\n",
    "# Replace NaN in data_num.item_description_len column by zeros\n",
    "data_num['item_description_len'] = data_num['item_description_len'].fillna(0)\n",
    "\n",
    "# Change data type of this column to uint16 provided the max val is less than 65535\n",
    "if (data_num.item_description_len.max() < 65535):\n",
    "    data_num['item_description_len'] = data_num['item_description_len'].astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function for making binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binary_columns(df_str, df_num, column_name):\n",
    "    \"\"\"\n",
    "    Turns a single column named column_name (with various categories) into m binary columns, where m is the number\n",
    "    of unique values in the original column. For each sample, the value for all new columns is 0 apart the one\n",
    "    that matches the value of the original column. Names of new binary columns are formed as follows:\n",
    "    column_name + '_' + str(original column value)\n",
    "    Inputs:\n",
    "        two pandas DataFrames: df_str where a single column contains information about given category\n",
    "                               df_num that will later contain many binary columns\n",
    "        column_name: name of the column that will be split into several binary columns\n",
    "    Returns nothing. It appends the collumns directly into df_num to increase performance.\n",
    "    \"\"\"\n",
    "    m = len(df_str)\n",
    "    if (m != len(df_num)):\n",
    "        raise Exception(\"df_str and df_num must have the same size.\")\n",
    " \n",
    "    categories = df_str[column_name].unique()\n",
    "\n",
    "    from tqdm import tqdm_notebook # progress bar\n",
    "\n",
    "    # Create a new feature for each category and initialize it to 0\n",
    "    for i in tqdm_notebook(categories, desc='1/2'):\n",
    "        df_num[column_name + '_' + str(i)] = np.zeros((m, 1), dtype=np.int8)\n",
    "\n",
    "#     Loop thorugh all rows and assign 1 to the column whose name is the same as category\n",
    "    for i in tqdm_notebook(df_str.index, desc='2/2'): # loop through all rows\n",
    "        category = str(df_str.at[i, column_name])\n",
    "        df_num.at[i, column_name + '_' + category] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### brand_name: for each unique one create new binary feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_binary_columns(data, data_num, 'brand_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main_cat, subcat_1, subcat_2: for each unique one create new binary feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_binary_columns(data, data_num, 'main_cat')\n",
    "make_binary_columns(data, data_num, 'subcat_1')\n",
    "make_binary_columns(data, data_num, 'subcat_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (settings['del']):\n",
    "    del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data and extract X, y and train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_unscaled, X_test_unscaled = train_test_split(data_num, test_size = settings['test_size'], random_state=settings['random_state']['split']) # randomly split data\n",
    "# ! X_train_unscaled and X_test_unscaled STILL CONTAINS PRICE AT THIS MOMENT !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (settings['del']):\n",
    "    del data_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pop price from X_train and X_test\n",
    "y_train = X_train_unscaled.pop('price')\n",
    "y_test = X_test_unscaled.pop('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pop id_train from both training and test data set\n",
    "\n",
    "id_train = X_train_unscaled.pop('train_id')\n",
    "id_test = X_test_unscaled.pop('train_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "X_train = X_train_unscaled.copy()\n",
    "X_test = X_test_unscaled.copy()\n",
    "\n",
    "columns_to_scale = ['name_len', 'item_condition_id', 'item_description_len']\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_train_unscaled[columns_to_scale]) # Compute the mean adn std of training data to be used for future scaling\n",
    "\n",
    "X_train[columns_to_scale] = pd.DataFrame(scaler.transform(X_train_unscaled[columns_to_scale]), index=X_train_unscaled.index, columns=columns_to_scale)\n",
    "if (settings['del']):\n",
    "    del X_train_unscaled\n",
    "\n",
    "X_test[columns_to_scale] = pd.DataFrame(scaler.transform(X_test_unscaled[columns_to_scale]), index=X_test_unscaled.index, columns=columns_to_scale)\n",
    "if (settings['del']):\n",
    "    del X_test_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_unscaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_unscaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.to_csv('X_train.csv')\n",
    "# X_train_scaled.to_csv('X_train_scaled.csv')\n",
    "# X_test.to_csv('X_test.csv')\n",
    "# X_test_scaled.to_csv('X_test_scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (settings['save_env']):\n",
    "    import dill                            #pip install dill --user\n",
    "    dill.dump_session('splittedData.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check size of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' By Fred Cirera, after https://stackoverflow.com/a/1094933/1870254'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name,value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name,sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance measure: RMSE\n",
    "\n",
    "$$\\text{RMSE} \\left( \\mathbf{Y} , \\mathbf{\\hat{Y}} \\right) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n \\left( y_i - \\hat{y_i} \\right)^2 } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_test, y_pred):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create directory and file for saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for saving data if it does not already exist\n",
    "import os\n",
    "\n",
    "if os.path.isdir('generated_data'):\n",
    "    print(\"Directory generated_data already exists\")\n",
    "else:\n",
    "    os.mkdir('generated_data')\n",
    "    print (\"Successfully created the directory called generated_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file with headings to save training and test RMSEs for learning curves\n",
    "import datetime\n",
    "filename = datetime.datetime.now().strftime('%y%m%d') + '_' + settings['filename_str'] # create file name starting with yymmdd_\n",
    "with open('generated_data/' + filename, 'w') as f:\n",
    "    f.write('training_set_size,training_error,test_error\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curve for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook # progress bar\n",
    "\n",
    "# Initialize arrays for plotting learning curves\n",
    "training_set_sizes = []\n",
    "train_rmses = []\n",
    "test_rmses = []\n",
    "\n",
    "# Generate learning curves and save them\n",
    "for m in tqdm_notebook(range(settings['learning_curve']['start'], settings['learning_curve']['stop'], settings['learning_curve']['step'])):\n",
    "    # Slice dataset\n",
    "    X_train_red = X_train[:m]\n",
    "    y_train_red = y_train[:m]\n",
    "    \n",
    "    # Applu linear regression\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lnr_regr = LinearRegression(n_jobs=-1)\n",
    "    print(\"Trainig for training set size of: \" + str(m) + \"...\")\n",
    "    lnr_regr.fit(X_train_red, y_train_red)\n",
    "    \n",
    "    # Make predictions and compute RMSEs\n",
    "    pred_train = lnr_regr.predict(X_train_red)\n",
    "    rmse_train = rmse(y_train_red, pred_train)\n",
    "    print(\"Training set RMSE: %.2f\" % rmse_train)\n",
    "    pred_test = lnr_regr.predict(X_test)\n",
    "    rmse_test = rmse(y_test, pred_test)\n",
    "    print(\"Training set RMSE: %.2f\" % rmse_test)\n",
    "    \n",
    "    # Save to csv file\n",
    "    print(\"Saving to file...\")\n",
    "    with open('generated_data/' + filename, 'a') as f:\n",
    "        f.write(str(m) + ',' + str(rmse_train) + ',' + str(rmse_test) +'\\n')\n",
    "    print(\"\")\n",
    "print(\"Done.\")\n",
    "print(\"Your training and test RMSEs are saved in generated_data/\" + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply linear regression to the full trainin set, compute training and test RMSE and add them to the file created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lnr_regr = LinearRegression(n_jobs=-1)\n",
    "print(\"Trainig...\")\n",
    "lnr_regr.fit(X_train, y_train)\n",
    "print(\"Training done.\")\n",
    "\n",
    "if (settings['save_env']):\n",
    "    dill.dump_session('linearModel.pkl')\n",
    "    \n",
    "# Make predictions and report train and test RMSEs\n",
    "\n",
    "print(\"Evaluating performance on the training set...\")\n",
    "pred_train = lnr_regr.predict(X_train)\n",
    "rmse_train = rmse(y_train, pred_train)\n",
    "print(\"Training set RMSE: %.2f\" % rmse_train)\n",
    "\n",
    "print(\"Evaluating performance on the test test...\")\n",
    "pred_test = lnr_regr.predict(X_test)\n",
    "rmse_test = rmse(y_test, pred_test)\n",
    "print(\"Test set RMSE: %.2f\" % rmse_test)\n",
    "\n",
    "# Save to csv file\n",
    "print(\"Saving to file...\")\n",
    "with open('generated_data/' + filename, 'a') as f:\n",
    "    f.write(str(len(X_train)) + ',' + str(rmse_train) + ',' + str(rmse_test) +'\\n')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1  # learning rate\n",
    "n_iterations = 1000\n",
    "m, n = X_train.shape\n",
    "\n",
    "X_b = np.c_[np.ones((m, 1)), X_train]  # add x0 = 1 to each instance\n",
    "\n",
    "theta = np.random.randn(n,1)  # random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (settings['del']):\n",
    "    del X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_iterations):\n",
    "    print(\"Iteration: \", i)\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    theta = theta - eta * gradients\n",
    "    pred = X_b * theta\n",
    "    rmse = rmse(y, pred)\n",
    "    print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_clf = SGDRegressor(penaly='none',)\n",
    "\n",
    "print(\"Trainig...\")\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "print(\"Training done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dill.load_session('linearModel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
